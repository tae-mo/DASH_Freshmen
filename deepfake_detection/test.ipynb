{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangyong/anaconda3/envs/deepfake/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n",
      "torch.Size([1, 4, 299, 299]) tensor([0])\n",
      "epoch : 1\n",
      "torch.Size([1, 4, 299, 299]) tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class DeepfakeDataset(Dataset):\n",
    "    def __init__(self, ds_name, train=True, transform=None):\n",
    "        self.path = os.path.join('/media/data1/sangyong/df_datasets/', ds_name)\n",
    "        if train:\n",
    "            self.real_path = os.path.join(self.path, 'train/real')\n",
    "            self.fake_path = os.path.join(self.path, 'train/rake')\n",
    "        else:\n",
    "            self.real_path = os.path.join(self.path, 'test/real')\n",
    "            self.fake_path = os.path.join(self.path, 'test/fake')\n",
    "            \n",
    "        self.real_list = glob(os.path.join(self.real_path, '**/*.png'))\n",
    "        self.fake_list = glob(os.path.join(self.fake_path, '**/*.png'))\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.img_list = self.real_list + self.fake_list\n",
    "        self.class_list = [0]*len(self.real_list) + [1]*len(self.fake_list)\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_list[idx]\n",
    "        label = self.class_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if not self.transform == None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(299)\n",
    "    ])\n",
    "    \n",
    "    dataset = DeepfakeDataset(ds_name=\"DeepFake\", train=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size=1,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False)\n",
    "    for epoch in range(2):\n",
    "        print(f\"epoch : {epoch}\")\n",
    "        for batch in dataloader:\n",
    "            img, label = batch\n",
    "            print(img.size(), label)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n"
     ]
    }
   ],
   "source": [
    "path = '/media/data1/sangyong/df_datasets/DeepFake'\n",
    "real_path = os.path.join(path, 'train/real')\n",
    "fake_path = os.path.join(path, 'train/fake')\n",
    "real_list = glob(os.path.join(real_path, '**/*.png'))\n",
    "fake_list = glob(os.path.join(fake_path, '**/*.png'))\n",
    "\n",
    "print(len(real_list), len(fake_list))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 149, 149]             864\n",
      "       BatchNorm2d-2         [-1, 32, 149, 149]              64\n",
      "              ReLU-3         [-1, 32, 149, 149]               0\n",
      "            Conv2d-4         [-1, 64, 149, 149]          18,432\n",
      "       BatchNorm2d-5         [-1, 64, 149, 149]             128\n",
      "              ReLU-6         [-1, 64, 149, 149]               0\n",
      "            Conv2d-7         [-1, 64, 149, 149]             576\n",
      "            Conv2d-8        [-1, 128, 149, 149]           8,192\n",
      "     SeparableConv-9        [-1, 128, 149, 149]               0\n",
      "      BatchNorm2d-10        [-1, 128, 149, 149]             256\n",
      "             ReLU-11        [-1, 128, 149, 149]               0\n",
      "           Conv2d-12        [-1, 128, 149, 149]           1,152\n",
      "           Conv2d-13        [-1, 128, 149, 149]          16,384\n",
      "    SeparableConv-14        [-1, 128, 149, 149]               0\n",
      "      BatchNorm2d-15        [-1, 128, 149, 149]             256\n",
      "        MaxPool2d-16          [-1, 128, 75, 75]               0\n",
      "           Conv2d-17          [-1, 128, 75, 75]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 75, 75]             256\n",
      "            Block-19          [-1, 128, 75, 75]               0\n",
      "             ReLU-20          [-1, 128, 75, 75]               0\n",
      "           Conv2d-21          [-1, 128, 75, 75]           1,152\n",
      "           Conv2d-22          [-1, 256, 75, 75]          32,768\n",
      "    SeparableConv-23          [-1, 256, 75, 75]               0\n",
      "      BatchNorm2d-24          [-1, 256, 75, 75]             512\n",
      "             ReLU-25          [-1, 256, 75, 75]               0\n",
      "           Conv2d-26          [-1, 256, 75, 75]           2,304\n",
      "           Conv2d-27          [-1, 256, 75, 75]          65,536\n",
      "    SeparableConv-28          [-1, 256, 75, 75]               0\n",
      "      BatchNorm2d-29          [-1, 256, 75, 75]             512\n",
      "        MaxPool2d-30          [-1, 256, 38, 38]               0\n",
      "           Conv2d-31          [-1, 256, 38, 38]          32,768\n",
      "      BatchNorm2d-32          [-1, 256, 38, 38]             512\n",
      "            Block-33          [-1, 256, 38, 38]               0\n",
      "             ReLU-34          [-1, 256, 38, 38]               0\n",
      "           Conv2d-35          [-1, 256, 38, 38]           2,304\n",
      "           Conv2d-36          [-1, 728, 38, 38]         186,368\n",
      "    SeparableConv-37          [-1, 728, 38, 38]               0\n",
      "      BatchNorm2d-38          [-1, 728, 38, 38]           1,456\n",
      "             ReLU-39          [-1, 728, 38, 38]               0\n",
      "           Conv2d-40          [-1, 728, 38, 38]           6,552\n",
      "           Conv2d-41          [-1, 728, 38, 38]         529,984\n",
      "    SeparableConv-42          [-1, 728, 38, 38]               0\n",
      "      BatchNorm2d-43          [-1, 728, 38, 38]           1,456\n",
      "        MaxPool2d-44          [-1, 728, 19, 19]               0\n",
      "           Conv2d-45          [-1, 728, 19, 19]         186,368\n",
      "      BatchNorm2d-46          [-1, 728, 19, 19]           1,456\n",
      "            Block-47          [-1, 728, 19, 19]               0\n",
      "             ReLU-48          [-1, 728, 19, 19]               0\n",
      "           Conv2d-49          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-50          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-51          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-52          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-53          [-1, 728, 19, 19]               0\n",
      "           Conv2d-54          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-55          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-56          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-57          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-58          [-1, 728, 19, 19]               0\n",
      "           Conv2d-59          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-60          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-61          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-62          [-1, 728, 19, 19]           1,456\n",
      "         Identity-63          [-1, 728, 19, 19]               0\n",
      "            Block-64          [-1, 728, 19, 19]               0\n",
      "             ReLU-65          [-1, 728, 19, 19]               0\n",
      "           Conv2d-66          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-67          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-68          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-69          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-70          [-1, 728, 19, 19]               0\n",
      "           Conv2d-71          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-72          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-73          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-74          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-75          [-1, 728, 19, 19]               0\n",
      "           Conv2d-76          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-77          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-78          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-79          [-1, 728, 19, 19]           1,456\n",
      "         Identity-80          [-1, 728, 19, 19]               0\n",
      "            Block-81          [-1, 728, 19, 19]               0\n",
      "             ReLU-82          [-1, 728, 19, 19]               0\n",
      "           Conv2d-83          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-84          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-85          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-86          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-87          [-1, 728, 19, 19]               0\n",
      "           Conv2d-88          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-89          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-90          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-91          [-1, 728, 19, 19]           1,456\n",
      "             ReLU-92          [-1, 728, 19, 19]               0\n",
      "           Conv2d-93          [-1, 728, 19, 19]           6,552\n",
      "           Conv2d-94          [-1, 728, 19, 19]         529,984\n",
      "    SeparableConv-95          [-1, 728, 19, 19]               0\n",
      "      BatchNorm2d-96          [-1, 728, 19, 19]           1,456\n",
      "         Identity-97          [-1, 728, 19, 19]               0\n",
      "            Block-98          [-1, 728, 19, 19]               0\n",
      "             ReLU-99          [-1, 728, 19, 19]               0\n",
      "          Conv2d-100          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-101          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-102          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-103          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-104          [-1, 728, 19, 19]               0\n",
      "          Conv2d-105          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-106          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-107          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-108          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-109          [-1, 728, 19, 19]               0\n",
      "          Conv2d-110          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-111          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-112          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-113          [-1, 728, 19, 19]           1,456\n",
      "        Identity-114          [-1, 728, 19, 19]               0\n",
      "           Block-115          [-1, 728, 19, 19]               0\n",
      "            ReLU-116          [-1, 728, 19, 19]               0\n",
      "          Conv2d-117          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-118          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-119          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-120          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-121          [-1, 728, 19, 19]               0\n",
      "          Conv2d-122          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-123          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-124          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-125          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-126          [-1, 728, 19, 19]               0\n",
      "          Conv2d-127          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-128          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-129          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-130          [-1, 728, 19, 19]           1,456\n",
      "        Identity-131          [-1, 728, 19, 19]               0\n",
      "           Block-132          [-1, 728, 19, 19]               0\n",
      "            ReLU-133          [-1, 728, 19, 19]               0\n",
      "          Conv2d-134          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-135          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-136          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-137          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-138          [-1, 728, 19, 19]               0\n",
      "          Conv2d-139          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-140          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-141          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-142          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-143          [-1, 728, 19, 19]               0\n",
      "          Conv2d-144          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-145          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-146          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-147          [-1, 728, 19, 19]           1,456\n",
      "        Identity-148          [-1, 728, 19, 19]               0\n",
      "           Block-149          [-1, 728, 19, 19]               0\n",
      "            ReLU-150          [-1, 728, 19, 19]               0\n",
      "          Conv2d-151          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-152          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-153          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-154          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-155          [-1, 728, 19, 19]               0\n",
      "          Conv2d-156          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-157          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-158          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-159          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-160          [-1, 728, 19, 19]               0\n",
      "          Conv2d-161          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-162          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-163          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-164          [-1, 728, 19, 19]           1,456\n",
      "        Identity-165          [-1, 728, 19, 19]               0\n",
      "           Block-166          [-1, 728, 19, 19]               0\n",
      "            ReLU-167          [-1, 728, 19, 19]               0\n",
      "          Conv2d-168          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-169          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-170          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-171          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-172          [-1, 728, 19, 19]               0\n",
      "          Conv2d-173          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-174          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-175          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-176          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-177          [-1, 728, 19, 19]               0\n",
      "          Conv2d-178          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-179          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-180          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-181          [-1, 728, 19, 19]           1,456\n",
      "        Identity-182          [-1, 728, 19, 19]               0\n",
      "           Block-183          [-1, 728, 19, 19]               0\n",
      "            ReLU-184          [-1, 728, 19, 19]               0\n",
      "          Conv2d-185          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-186          [-1, 728, 19, 19]         529,984\n",
      "   SeparableConv-187          [-1, 728, 19, 19]               0\n",
      "     BatchNorm2d-188          [-1, 728, 19, 19]           1,456\n",
      "            ReLU-189          [-1, 728, 19, 19]               0\n",
      "          Conv2d-190          [-1, 728, 19, 19]           6,552\n",
      "          Conv2d-191         [-1, 1024, 19, 19]         745,472\n",
      "   SeparableConv-192         [-1, 1024, 19, 19]               0\n",
      "     BatchNorm2d-193         [-1, 1024, 19, 19]           2,048\n",
      "       MaxPool2d-194         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-195         [-1, 1024, 10, 10]         745,472\n",
      "     BatchNorm2d-196         [-1, 1024, 10, 10]           2,048\n",
      "           Block-197         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-198         [-1, 1024, 10, 10]           9,216\n",
      "          Conv2d-199         [-1, 1536, 10, 10]       1,572,864\n",
      "   SeparableConv-200         [-1, 1536, 10, 10]               0\n",
      "     BatchNorm2d-201         [-1, 1536, 10, 10]           3,072\n",
      "            ReLU-202         [-1, 1536, 10, 10]               0\n",
      "          Conv2d-203         [-1, 1536, 10, 10]          13,824\n",
      "          Conv2d-204         [-1, 2048, 10, 10]       3,145,728\n",
      "   SeparableConv-205         [-1, 2048, 10, 10]               0\n",
      "     BatchNorm2d-206         [-1, 2048, 10, 10]           4,096\n",
      "            ReLU-207         [-1, 2048, 10, 10]               0\n",
      "AdaptiveAvgPool2d-208           [-1, 2048, 1, 1]               0\n",
      "          Linear-209                    [-1, 2]           4,098\n",
      "================================================================\n",
      "Total params: 20,811,050\n",
      "Trainable params: 20,811,050\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.02\n",
      "Forward/backward pass size (MB): 754.24\n",
      "Params size (MB): 79.39\n",
      "Estimated Total Size (MB): 834.65\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Xception(\n",
      "  (module1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (module2): Block(\n",
      "    (skip): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "        (depthwiseconv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (depthwiseconv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (module3): Block(\n",
      "    (skip): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "        (depthwiseconv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (depthwiseconv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (module4): Block(\n",
      "    (skip): Sequential(\n",
      "      (0): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (depthwiseconv): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (module5_12): Sequential(\n",
      "    (0): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Block(\n",
      "      (skip): Identity()\n",
      "      (layers): Sequential(\n",
      "        (0): ReLU(inplace=True)\n",
      "        (1): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (5): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU(inplace=True)\n",
      "        (7): SeparableConv(\n",
      "          (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (8): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (module13): Block(\n",
      "    (skip): Sequential(\n",
      "      (0): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): ReLU(inplace=True)\n",
      "      (1): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (depthwiseconv): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): SeparableConv(\n",
      "        (pointwiseconv): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (depthwiseconv): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (module14): Sequential(\n",
      "    (0): SeparableConv(\n",
      "      (pointwiseconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "      (depthwiseconv): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): SeparableConv(\n",
      "      (pointwiseconv): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "      (depthwiseconv): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): AdaptiveAvgPool2d(output_size=1)\n",
      "  )\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, strides=1, padding=0, dilation=1, bias=False):\n",
    "        super(SeparableConv, self).__init__()\n",
    "        \n",
    "        # https://gaussian37.github.io/dl-pytorch-conv2d/ dilation, groups 설명\n",
    "        self.pointwiseconv = nn.Conv2d(in_channels, in_channels, kernel_size, strides, padding, dilation, groups=in_channels, bias=bias)\n",
    "        self.depthwiseconv = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, 1, bias=bias)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.pointwiseconv(x)\n",
    "        x = self.depthwiseconv(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, repeat, strides=1, start_with_relu=True, sizeup_first=True):\n",
    "        super(Block, self).__init__()\n",
    "        \n",
    "        if out_channels != in_channels or strides != 1:\n",
    "            self.skip = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=strides, bias=False), # bias를 False를 두는 이유???\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.skip = nn.Identity()\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        channels = in_channels\n",
    "        if sizeup_first:\n",
    "            layers.append(nn.ReLU(inplace=True)) # inplace=True 하면, inplace 연산을 수행함, inplace 연산은 결과값을 새로운 변수에 값을 저장하는 대신 기존의 데이터를 대체하는것을 의미 메모리적 이득\n",
    "            layers.append(SeparableConv(in_channels, out_channels, kernel_size=3, strides=1, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            channels = out_channels\n",
    "            \n",
    "        for i in range(repeat-1):\n",
    "            layers.append(nn.ReLU(inplace=True)) # 근데 왜 굳이 해야 해? 안하면 안 될 정도?\n",
    "            layers.append(SeparableConv(channels, channels, kernel_size=3, strides=1, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(channels))\n",
    "            \n",
    "        if not sizeup_first:\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(SeparableConv(channels, out_channels, kernel_size=3, strides=1, padding=1, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(out_channels))\n",
    "            \n",
    "        if not start_with_relu:\n",
    "            layers = layers[1:]\n",
    "        else:\n",
    "            layers[0] = nn.ReLU(inplace=True) # 다시 한번 확실하게 ReLU로 시작하게 하자\n",
    "                    \n",
    "        if strides != 1:\n",
    "            layers.append(nn.MaxPool2d(3, strides, 1)) # padding을 1로 둠으로서 image shape을 논문과 같이 19X19로 만듦. 근데 self.skip에서 18X18로 나오는거 같은데 어케되는거지\n",
    "            \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x = self.layers(img)\n",
    "        x = x + self.skip(img)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Xception(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Xception, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Entry flow\n",
    "        self.module1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32,64,3,1,1,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.module2 = Block(64, 128, 2, 2, False, True)\n",
    "        self.module3 = Block(128, 256, 2, 2, True, True)\n",
    "        self.module4 = Block(256, 728, 2, 2, True, True)\n",
    "        \n",
    "        # Middle flow\n",
    "        self.module5_12 = nn.Sequential(*[Block(728,728,3,1,True,True) for _ in range(8)])\n",
    "        \n",
    "        # Exit flow\n",
    "        self.module13 = Block(728, 1024, 2, 2, True, False)\n",
    "        self.module14 = nn.Sequential(\n",
    "            SeparableConv(1024, 1536, 3, 1, 1),\n",
    "            nn.BatchNorm2d(1536),\n",
    "            nn.ReLU(inplace=True),\n",
    "            SeparableConv(1536, 2048, 3, 1, 1),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        \n",
    "        # classifier\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, img):\n",
    "        x = self.module1(img)\n",
    "        x = self.module2(x)\n",
    "        x = self.module3(x)\n",
    "        x = self.module4(x)\n",
    "        x = self.module5_12(x)\n",
    "        x = self.module13(x)\n",
    "        x = self.module14(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "import torchsummary\n",
    "model = Xception(2)\n",
    "print(torchsummary.summary(model, (3,299,299), device='cpu'))\n",
    "print(model)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "type(datetime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from utils import *\n",
    "from Train import *\n",
    "from model.xception import Xception\n",
    "from data import get_dataloader\n",
    "\n",
    "def build_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    #### dataset ####\n",
    "    parser.add_argument(\"--data_name\", type=str, default=\"DeepFake\",\n",
    "                        choices=['DeepFake', 'DeepFakeDetection', 'Face2Face', 'FaceSwap', 'NeuralTextures'])\n",
    "    parser.add_argument(\"--data_path\", type=str, default='/media/data1/sangyong/df_datasets')\n",
    "    parser.add_argument(\"--n_workers\", type=int, default=4)\n",
    "    #### train & test ####\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--model\", type=str, default=\"xception\", choices=[\"xception\", \"clrnet\"])\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"SGD\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.01)\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=5e-4)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=30)\n",
    "    #### save & load ####\n",
    "    parser.add_argument(\"--save_root_dir\", type=str, default='/media/data1/sangyong/deepfake_detection/save')\n",
    "    parser.add_argument(\"--model_load_path\", default=None)\n",
    "    parser.add_argument(\"--print_freq\", type=int, default=100)\n",
    "    parser.add_argument(\"--world_size\", type=int, default=4)\n",
    "    parser.add_argument(\"--DDP\", action=\"store_true\")\n",
    "    parser.add_argument(\"--dist_backend\", type=str, default='nccl')\n",
    "    parser.add_argument(\"--use_wandb\", default=False)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.DDP:\n",
    "        args.local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "        args.batch_size = args.batch_size // args.world_size\n",
    "    else:\n",
    "        args.local_rank = 0\n",
    "    args.save_name = f\"[data-{args.data_name}]_[bs-{args.batch_size}]_\"+\\\n",
    "                     f\"[m-{args.model}]_[optim-{args.optimizer}]_[date-{dt.now().strftime('%Y%m%d')}]\"\n",
    "    args.save_dir = os.path.join(args.save_root_dir, args.save_name)\n",
    "    args.model_save_dir = os.path.join(args.save_dir, \"save_model\")\n",
    "    args.logger_path = os.path.join(args.save_dir, \"log.txt\")\n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "    os.makedirs(args.model_save_dir, exist_ok=True)\n",
    "    return args\n",
    "\n",
    "def main(args, logger):\n",
    "    if args.model == \"xception\":\n",
    "        model = Xception(num_classes=2).cuda(args.local_rank)\n",
    "    elif args.model == \"clrnet\":\n",
    "        model = None\n",
    "    \n",
    "    train_loader, valid_loader, train_sampler = get_dataloader(args)\n",
    "    \n",
    "    if args.DDP:\n",
    "        # model backward pass에 연관되지 않은 parameter들을 mark해서 DDP가 해당 파라미터들의 gradient들을 영원히 기다리는 것을 방지 한다. \n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], find_unused_parameters=True) \n",
    "\n",
    "    if args.optimizer == \"SGD\":\n",
    "        optimizer = torch.optim.SGD(\n",
    "            params=model.parameters(),\n",
    "            lr = args.lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=args.weight_decay,\n",
    "            nesterov=True\n",
    "        )\n",
    "    elif args.optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=model.parameters(),\n",
    "            lr = args.lr,\n",
    "            weight_decay=args.weight_decay,\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f\"optimizer {args.optimzier} is not implemented. please change\")\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    start_epoch = 1\n",
    "    best_acc = -1\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    if args.model_load_path:\n",
    "        logger.write(f\"model load from {args.model_load_path}\\n\")\n",
    "        if not args.DDP:\n",
    "            checkpoint = torch.load(args.model_load_path)\n",
    "        else:\n",
    "            dist.barrier()\n",
    "            checkpoint = torch.load(args.model_load_path, map_location={\"cuda:0\": f\"cuda:{args.local_rank}\"})\n",
    "            \n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_acc = checkpoint['best_acc']\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        logger.write(f\"model is successfully loaded\\n\"\n",
    "                     f\"start epoch: {start_epoch}, best_acc: {best_acc}\")\n",
    "        \n",
    "        del checkpoint\n",
    "    \n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        if args.DDP:\n",
    "            train_sampler.set_epoch(epoch)\n",
    "            \n",
    "        train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "        \n",
    "        valid_loss, valid_acc = validate(valid_loader, model, criterion, args)\n",
    "        \n",
    "        if args.local_rank == 0:\n",
    "            if valid_acc > best_acc:\n",
    "                logger.write(f\"Best accuracy: {best_acc:.4f} -> {valid_acc:.4f}\")\n",
    "                best_acc = valid_acc\n",
    "                checkpoint_dict = {\n",
    "                    \"model\": model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"best_acc\": best_acc\n",
    "                }\n",
    "                model_save_path = os.path.join(args.model_save_dir, f\"{epoch}_{best_acc}.pth\")\n",
    "                torch.save(checkpoint_dict, model_save_path)\n",
    "            logger.write(f\"[Epoch-{epoch}]_[Train accuracy-{train_acc}]_\"\n",
    "                          f\"[Train loss-{train_loss:.4f}]_[Valid loss-{valid_loss}]\")\n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "            \n",
    "            if args.use_wandb:\n",
    "                wandb_msg = {\"Train acc\": train_acc,\n",
    "                             \"valid acc\": valid_acc,\n",
    "                             \"Train loss\": train_loss,\n",
    "                             \"valid loss\": valid_loss}\n",
    "                wandb.log(wandb_msg)\n",
    "        logger.write(f\"[Best accuracy-{best_acc}]_[Best loss-{best_loss}]\")\n",
    "        scheduler.step()\n",
    "        dist.barrier()\n",
    "        \n",
    "args = build_args()\n",
    "logger = Logger(args.local_rank)\n",
    "logger.open(args.logger_path)\n",
    "print_args(args, logger=logger)\n",
    "if args.use_wandb and args.local_rank ==0:\n",
    "    wandb.init(project=\"Deepfake Detection\", name=args.save_name, notes=args.save_name)\n",
    "    wandb.config.update(args)\n",
    "if args.DDP:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend)\n",
    "    logger.write(f'DDP using {args.world_size} GPUS\\n')\n",
    "start_time = time.time()\n",
    "if args.data_name in ['DeepFake', 'DeepFakeDetection', 'Face2Face', 'FaceSwap', 'NeuralTextures']:\n",
    "    main(args, logger)\n",
    "else:\n",
    "    raise NotImplementedError(f\"data {args.data_name} is not implemented\")\n",
    "\n",
    "logger.write(f\"total time: {time.time() - start_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19c6e6602282f0050132c5ee3f6060025b52eb83d27c2cfc5885fe6c9e7b8d05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
