{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/home/data/Imagenet')\n",
    "train_path = root / 'train'\n",
    "val_path = root / 'val'\n",
    "label_path = root / 'label'\n",
    "\n",
    "def ImgNetData(train_path, val_path, distributed=True):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.RandomChoice([transforms.Resize(256), transforms.Resize(480)]),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        \n",
    "        ### 이걸로 사용해볼 순 없나?\n",
    "        # transforms.RandomResizedCrop((224,224)),\n",
    "        # transforms.Resize((256,256)),\n",
    "        # transforms.CenterCrop((224,224)),\n",
    "        \n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "    ])\n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(244),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    train_data = ImageFolder(root=train_path, transform=train_transforms)\n",
    "    val_data = ImageFolder(root=val_path, transform=val_transforms)\n",
    "    \n",
    "    return train_data, val_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n01440764': 'tench',\n",
       " 'n01443537': 'goldfish',\n",
       " 'n01484850': 'great',\n",
       " 'n01491361': 'tiger',\n",
       " 'n01494475': 'hammerhead',\n",
       " 'n01496331': 'electric',\n",
       " 'n01498041': 'stingray',\n",
       " 'n01514668': 'cock',\n",
       " 'n01514859': 'hen',\n",
       " 'n01518878': 'ostrich',\n",
       " 'n01530575': 'brambling',\n",
       " 'n01531178': 'goldfinch',\n",
       " 'n01532829': 'house',\n",
       " 'n01534433': 'junco',\n",
       " 'n01537544': 'indigo',\n",
       " 'n01558993': 'robin',\n",
       " 'n01560419': 'bulbul',\n",
       " 'n01580077': 'jay',\n",
       " 'n01582220': 'magpie',\n",
       " 'n01592084': 'chickadee',\n",
       " 'n01601694': 'water',\n",
       " 'n01608432': 'kite',\n",
       " 'n01614925': 'bald',\n",
       " 'n01616318': 'vulture',\n",
       " 'n01622779': 'great',\n",
       " 'n01629819': 'European',\n",
       " 'n01630670': 'common',\n",
       " 'n01631663': 'eft',\n",
       " 'n01632458': 'spotted',\n",
       " 'n01632777': 'axolotl',\n",
       " 'n01641577': 'bullfrog',\n",
       " 'n01644373': 'tree',\n",
       " 'n01644900': 'tailed',\n",
       " 'n01664065': 'loggerhead',\n",
       " 'n01665541': 'leatherback',\n",
       " 'n01667114': 'mud',\n",
       " 'n01667778': 'terrapin',\n",
       " 'n01669191': 'box',\n",
       " 'n01675722': 'banded',\n",
       " 'n01677366': 'common',\n",
       " 'n01682714': 'American',\n",
       " 'n01685808': 'whiptail',\n",
       " 'n01687978': 'agama',\n",
       " 'n01688243': 'frilled',\n",
       " 'n01689811': 'alligator',\n",
       " 'n01692333': 'Gila',\n",
       " 'n01693334': 'green',\n",
       " 'n01694178': 'African',\n",
       " 'n01695060': 'Komodo',\n",
       " 'n01697457': 'African',\n",
       " 'n01698640': 'American',\n",
       " 'n01704323': 'triceratops',\n",
       " 'n01728572': 'thunder',\n",
       " 'n01728920': 'ringneck',\n",
       " 'n01729322': 'hognose',\n",
       " 'n01729977': 'green',\n",
       " 'n01734418': 'king',\n",
       " 'n01735189': 'garter',\n",
       " 'n01737021': 'water',\n",
       " 'n01739381': 'vine',\n",
       " 'n01740131': 'night',\n",
       " 'n01742172': 'boa',\n",
       " 'n01744401': 'rock',\n",
       " 'n01748264': 'Indian',\n",
       " 'n01749939': 'green',\n",
       " 'n01751748': 'sea',\n",
       " 'n01753488': 'horned',\n",
       " 'n01755581': 'diamondback',\n",
       " 'n01756291': 'sidewinder',\n",
       " 'n01768244': 'trilobite',\n",
       " 'n01770081': 'harvestman',\n",
       " 'n01770393': 'scorpion',\n",
       " 'n01773157': 'black',\n",
       " 'n01773549': 'barn',\n",
       " 'n01773797': 'garden',\n",
       " 'n01774384': 'black',\n",
       " 'n01774750': 'tarantula',\n",
       " 'n01775062': 'wolf',\n",
       " 'n01776313': 'tick',\n",
       " 'n01784675': 'centipede',\n",
       " 'n01795545': 'black',\n",
       " 'n01796340': 'ptarmigan',\n",
       " 'n01797886': 'ruffed',\n",
       " 'n01798484': 'prairie',\n",
       " 'n01806143': 'peacock',\n",
       " 'n01806567': 'quail',\n",
       " 'n01807496': 'partridge',\n",
       " 'n01817953': 'African',\n",
       " 'n01818515': 'macaw',\n",
       " 'n01819313': 'sulphurcrested',\n",
       " 'n01820546': 'lorikeet',\n",
       " 'n01824575': 'coucal',\n",
       " 'n01828970': 'bee',\n",
       " 'n01829413': 'hornbill',\n",
       " 'n01833805': 'hummingbird',\n",
       " 'n01843065': 'jacamar',\n",
       " 'n01843383': 'toucan',\n",
       " 'n01847000': 'drake',\n",
       " 'n01855032': 'redbreasted',\n",
       " 'n01855672': 'goose',\n",
       " 'n01860187': 'black',\n",
       " 'n01871265': 'tusker',\n",
       " 'n01872401': 'echidna',\n",
       " 'n01873310': 'platypus',\n",
       " 'n01877812': 'wallaby',\n",
       " 'n01882714': 'koala',\n",
       " 'n01883070': 'wombat',\n",
       " 'n01910747': 'jellyfish',\n",
       " 'n01914609': 'sea',\n",
       " 'n01917289': 'brain',\n",
       " 'n01924916': 'flatworm',\n",
       " 'n01930112': 'nematode',\n",
       " 'n01943899': 'conch',\n",
       " 'n01944390': 'snail',\n",
       " 'n01945685': 'slug',\n",
       " 'n01950731': 'sea',\n",
       " 'n01955084': 'chiton',\n",
       " 'n01968897': 'chambered',\n",
       " 'n01978287': 'Dungeness',\n",
       " 'n01978455': 'rock',\n",
       " 'n01980166': 'fiddler',\n",
       " 'n01981276': 'king',\n",
       " 'n01983481': 'American',\n",
       " 'n01984695': 'spiny',\n",
       " 'n01985128': 'crayfish',\n",
       " 'n01986214': 'hermit',\n",
       " 'n01990800': 'isopod',\n",
       " 'n02002556': 'white',\n",
       " 'n02002724': 'black',\n",
       " 'n02006656': 'spoonbill',\n",
       " 'n02007558': 'flamingo',\n",
       " 'n02009229': 'little',\n",
       " 'n02009912': 'American',\n",
       " 'n02011460': 'bittern',\n",
       " 'n02012849': 'crane',\n",
       " 'n02013706': 'limpkin',\n",
       " 'n02017213': 'European',\n",
       " 'n02018207': 'American',\n",
       " 'n02018795': 'bustard',\n",
       " 'n02025239': 'ruddy',\n",
       " 'n02027492': 'redbacked',\n",
       " 'n02028035': 'redshank',\n",
       " 'n02033041': 'dowitcher',\n",
       " 'n02037110': 'oystercatcher',\n",
       " 'n02051845': 'pelican',\n",
       " 'n02056570': 'king',\n",
       " 'n02058221': 'albatross',\n",
       " 'n02066245': 'grey',\n",
       " 'n02071294': 'killer',\n",
       " 'n02074367': 'dugong',\n",
       " 'n02077923': 'sea',\n",
       " 'n02085620': 'Chihuahua',\n",
       " 'n02085782': 'Japanese',\n",
       " 'n02085936': 'Maltese',\n",
       " 'n02086079': 'Pekinese',\n",
       " 'n02086240': 'ShihTzu',\n",
       " 'n02086646': 'Blenheim',\n",
       " 'n02086910': 'papillon',\n",
       " 'n02087046': 'toy',\n",
       " 'n02087394': 'Rhodesian',\n",
       " 'n02088094': 'Afghan',\n",
       " 'n02088238': 'basset',\n",
       " 'n02088364': 'beagle',\n",
       " 'n02088466': 'bloodhound',\n",
       " 'n02088632': 'bluetick',\n",
       " 'n02089078': 'blackandtan',\n",
       " 'n02089867': 'Walker',\n",
       " 'n02089973': 'English',\n",
       " 'n02090379': 'redbone',\n",
       " 'n02090622': 'borzoi',\n",
       " 'n02090721': 'Irish',\n",
       " 'n02091032': 'Italian',\n",
       " 'n02091134': 'whippet',\n",
       " 'n02091244': 'Ibizan',\n",
       " 'n02091467': 'Norwegian',\n",
       " 'n02091635': 'otterhound',\n",
       " 'n02091831': 'Saluki',\n",
       " 'n02092002': 'Scottish',\n",
       " 'n02092339': 'Weimaraner',\n",
       " 'n02093256': 'Staffordshire',\n",
       " 'n02093428': 'American',\n",
       " 'n02093647': 'Bedlington',\n",
       " 'n02093754': 'Border',\n",
       " 'n02093859': 'Kerry',\n",
       " 'n02093991': 'Irish',\n",
       " 'n02094114': 'Norfolk',\n",
       " 'n02094258': 'Norwich',\n",
       " 'n02094433': 'Yorkshire',\n",
       " 'n02095314': 'wirehaired',\n",
       " 'n02095570': 'Lakeland',\n",
       " 'n02095889': 'Sealyham',\n",
       " 'n02096051': 'Airedale',\n",
       " 'n02096177': 'cairn',\n",
       " 'n02096294': 'Australian',\n",
       " 'n02096437': 'Dandie',\n",
       " 'n02096585': 'Boston',\n",
       " 'n02097047': 'miniature',\n",
       " 'n02097130': 'giant',\n",
       " 'n02097209': 'standard',\n",
       " 'n02097298': 'Scotch',\n",
       " 'n02097474': 'Tibetan',\n",
       " 'n02097658': 'silky',\n",
       " 'n02098105': 'softcoated',\n",
       " 'n02098286': 'West',\n",
       " 'n02098413': 'Lhasa',\n",
       " 'n02099267': 'flatcoated',\n",
       " 'n02099429': 'curlycoated',\n",
       " 'n02099601': 'golden',\n",
       " 'n02099712': 'Labrador',\n",
       " 'n02099849': 'Chesapeake',\n",
       " 'n02100236': 'German',\n",
       " 'n02100583': 'vizsla',\n",
       " 'n02100735': 'English',\n",
       " 'n02100877': 'Irish',\n",
       " 'n02101006': 'Gordon',\n",
       " 'n02101388': 'Brittany',\n",
       " 'n02101556': 'clumber',\n",
       " 'n02102040': 'English',\n",
       " 'n02102177': 'Welsh',\n",
       " 'n02102318': 'cocker',\n",
       " 'n02102480': 'Sussex',\n",
       " 'n02102973': 'Irish',\n",
       " 'n02104029': 'kuvasz',\n",
       " 'n02104365': 'schipperke',\n",
       " 'n02105056': 'groenendael',\n",
       " 'n02105162': 'malinois',\n",
       " 'n02105251': 'briard',\n",
       " 'n02105412': 'kelpie',\n",
       " 'n02105505': 'komondor',\n",
       " 'n02105641': 'Old',\n",
       " 'n02105855': 'Shetland',\n",
       " 'n02106030': 'collie',\n",
       " 'n02106166': 'Border',\n",
       " 'n02106382': 'Bouvier',\n",
       " 'n02106550': 'Rottweiler',\n",
       " 'n02106662': 'German',\n",
       " 'n02107142': 'Doberman',\n",
       " 'n02107312': 'miniature',\n",
       " 'n02107574': 'Greater',\n",
       " 'n02107683': 'Bernese',\n",
       " 'n02107908': 'Appenzeller',\n",
       " 'n02108000': 'EntleBucher',\n",
       " 'n02108089': 'boxer',\n",
       " 'n02108422': 'bull',\n",
       " 'n02108551': 'Tibetan',\n",
       " 'n02108915': 'French',\n",
       " 'n02109047': 'Great',\n",
       " 'n02109525': 'Saint',\n",
       " 'n02109961': 'Eskimo',\n",
       " 'n02110063': 'malamute',\n",
       " 'n02110185': 'Siberian',\n",
       " 'n02110341': 'dalmatian',\n",
       " 'n02110627': 'affenpinscher',\n",
       " 'n02110806': 'basenji',\n",
       " 'n02110958': 'pug',\n",
       " 'n02111129': 'Leonberg',\n",
       " 'n02111277': 'Newfoundland',\n",
       " 'n02111500': 'Great',\n",
       " 'n02111889': 'Samoyed',\n",
       " 'n02112018': 'Pomeranian',\n",
       " 'n02112137': 'chow',\n",
       " 'n02112350': 'keeshond',\n",
       " 'n02112706': 'Brabancon',\n",
       " 'n02113023': 'Pembroke',\n",
       " 'n02113186': 'Cardigan',\n",
       " 'n02113624': 'toy',\n",
       " 'n02113712': 'miniature',\n",
       " 'n02113799': 'standard',\n",
       " 'n02113978': 'Mexican',\n",
       " 'n02114367': 'timber',\n",
       " 'n02114548': 'white',\n",
       " 'n02114712': 'red',\n",
       " 'n02114855': 'coyote',\n",
       " 'n02115641': 'dingo',\n",
       " 'n02115913': 'dhole',\n",
       " 'n02116738': 'African',\n",
       " 'n02117135': 'hyena',\n",
       " 'n02119022': 'red',\n",
       " 'n02119789': 'kit',\n",
       " 'n02120079': 'Arctic',\n",
       " 'n02120505': 'grey',\n",
       " 'n02123045': 'tabby',\n",
       " 'n02123159': 'tiger',\n",
       " 'n02123394': 'Persian',\n",
       " 'n02123597': 'Siamese',\n",
       " 'n02124075': 'Egyptian',\n",
       " 'n02125311': 'cougar',\n",
       " 'n02127052': 'lynx',\n",
       " 'n02128385': 'leopard',\n",
       " 'n02128757': 'snow',\n",
       " 'n02128925': 'jaguar',\n",
       " 'n02129165': 'lion',\n",
       " 'n02129604': 'tiger',\n",
       " 'n02130308': 'cheetah',\n",
       " 'n02132136': 'brown',\n",
       " 'n02133161': 'American',\n",
       " 'n02134084': 'ice',\n",
       " 'n02134418': 'sloth',\n",
       " 'n02137549': 'mongoose',\n",
       " 'n02138441': 'meerkat',\n",
       " 'n02165105': 'tiger',\n",
       " 'n02165456': 'ladybug',\n",
       " 'n02167151': 'ground',\n",
       " 'n02168699': 'longhorned',\n",
       " 'n02169497': 'leaf',\n",
       " 'n02172182': 'dung',\n",
       " 'n02174001': 'rhinoceros',\n",
       " 'n02177972': 'weevil',\n",
       " 'n02190166': 'fly',\n",
       " 'n02206856': 'bee',\n",
       " 'n02219486': 'ant',\n",
       " 'n02226429': 'grasshopper',\n",
       " 'n02229544': 'cricket',\n",
       " 'n02231487': 'walking',\n",
       " 'n02233338': 'cockroach',\n",
       " 'n02236044': 'mantis',\n",
       " 'n02256656': 'cicada',\n",
       " 'n02259212': 'leafhopper',\n",
       " 'n02264363': 'lacewing',\n",
       " 'n02268443': 'dragonfly',\n",
       " 'n02268853': 'damselfly',\n",
       " 'n02276258': 'admiral',\n",
       " 'n02277742': 'ringlet',\n",
       " 'n02279972': 'monarch',\n",
       " 'n02280649': 'cabbage',\n",
       " 'n02281406': 'sulphur',\n",
       " 'n02281787': 'lycaenid',\n",
       " 'n02317335': 'starfish',\n",
       " 'n02319095': 'sea',\n",
       " 'n02321529': 'sea',\n",
       " 'n02325366': 'wood',\n",
       " 'n02326432': 'hare',\n",
       " 'n02328150': 'Angora',\n",
       " 'n02342885': 'hamster',\n",
       " 'n02346627': 'porcupine',\n",
       " 'n02356798': 'fox',\n",
       " 'n02361337': 'marmot',\n",
       " 'n02363005': 'beaver',\n",
       " 'n02364673': 'guinea',\n",
       " 'n02389026': 'sorrel',\n",
       " 'n02391049': 'zebra',\n",
       " 'n02395406': 'hog',\n",
       " 'n02396427': 'wild',\n",
       " 'n02397096': 'warthog',\n",
       " 'n02398521': 'hippopotamus',\n",
       " 'n02403003': 'ox',\n",
       " 'n02408429': 'water',\n",
       " 'n02410509': 'bison',\n",
       " 'n02412080': 'ram',\n",
       " 'n02415577': 'bighorn',\n",
       " 'n02417914': 'ibex',\n",
       " 'n02422106': 'hartebeest',\n",
       " 'n02422699': 'impala',\n",
       " 'n02423022': 'gazelle',\n",
       " 'n02437312': 'Arabian',\n",
       " 'n02437616': 'llama',\n",
       " 'n02441942': 'weasel',\n",
       " 'n02442845': 'mink',\n",
       " 'n02443114': 'polecat',\n",
       " 'n02443484': 'blackfooted',\n",
       " 'n02444819': 'otter',\n",
       " 'n02445715': 'skunk',\n",
       " 'n02447366': 'badger',\n",
       " 'n02454379': 'armadillo',\n",
       " 'n02457408': 'threetoed',\n",
       " 'n02480495': 'orangutan',\n",
       " 'n02480855': 'gorilla',\n",
       " 'n02481823': 'chimpanzee',\n",
       " 'n02483362': 'gibbon',\n",
       " 'n02483708': 'siamang',\n",
       " 'n02484975': 'guenon',\n",
       " 'n02486261': 'patas',\n",
       " 'n02486410': 'baboon',\n",
       " 'n02487347': 'macaque',\n",
       " 'n02488291': 'langur',\n",
       " 'n02488702': 'colobus',\n",
       " 'n02489166': 'proboscis',\n",
       " 'n02490219': 'marmoset',\n",
       " 'n02492035': 'capuchin',\n",
       " 'n02492660': 'howler',\n",
       " 'n02493509': 'titi',\n",
       " 'n02493793': 'spider',\n",
       " 'n02494079': 'squirrel',\n",
       " 'n02497673': 'Madagascar',\n",
       " 'n02500267': 'indri',\n",
       " 'n02504013': 'Indian',\n",
       " 'n02504458': 'African',\n",
       " 'n02509815': 'lesser',\n",
       " 'n02510455': 'giant',\n",
       " 'n02514041': 'barracouta',\n",
       " 'n02526121': 'eel',\n",
       " 'n02536864': 'coho',\n",
       " 'n02606052': 'rock',\n",
       " 'n02607072': 'anemone',\n",
       " 'n02640242': 'sturgeon',\n",
       " 'n02641379': 'gar',\n",
       " 'n02643566': 'lionfish',\n",
       " 'n02655020': 'puffer',\n",
       " 'n02666196': 'abacus',\n",
       " 'n02667093': 'abaya',\n",
       " 'n02669723': 'academic',\n",
       " 'n02672831': 'accordion',\n",
       " 'n02676566': 'acoustic',\n",
       " 'n02687172': 'aircraft',\n",
       " 'n02690373': 'airliner',\n",
       " 'n02692877': 'airship',\n",
       " 'n02699494': 'altar',\n",
       " 'n02701002': 'ambulance',\n",
       " 'n02704792': 'amphibian',\n",
       " 'n02708093': 'analog',\n",
       " 'n02727426': 'apiary',\n",
       " 'n02730930': 'apron',\n",
       " 'n02747177': 'ashcan',\n",
       " 'n02749479': 'assault',\n",
       " 'n02769748': 'backpack',\n",
       " 'n02776631': 'bakery',\n",
       " 'n02777292': 'balance',\n",
       " 'n02782093': 'balloon',\n",
       " 'n02783161': 'ballpoint',\n",
       " 'n02786058': 'Band',\n",
       " 'n02787622': 'banjo',\n",
       " 'n02788148': 'bannister',\n",
       " 'n02790996': 'barbell',\n",
       " 'n02791124': 'barber',\n",
       " 'n02791270': 'barbershop',\n",
       " 'n02793495': 'barn',\n",
       " 'n02794156': 'barometer',\n",
       " 'n02795169': 'barrel',\n",
       " 'n02797295': 'barrow',\n",
       " 'n02799071': 'baseball',\n",
       " 'n02802426': 'basketball',\n",
       " 'n02804414': 'bassinet',\n",
       " 'n02804610': 'bassoon',\n",
       " 'n02807133': 'bathing',\n",
       " 'n02808304': 'bath',\n",
       " 'n02808440': 'bathtub',\n",
       " 'n02814533': 'beach',\n",
       " 'n02814860': 'beacon',\n",
       " 'n02815834': 'beaker',\n",
       " 'n02817516': 'bearskin',\n",
       " 'n02823428': 'beer',\n",
       " 'n02823750': 'beer',\n",
       " 'n02825657': 'bell',\n",
       " 'n02834397': 'bib',\n",
       " 'n02835271': 'bicyclebuiltfortwo',\n",
       " 'n02837789': 'bikini',\n",
       " 'n02840245': 'binder',\n",
       " 'n02841315': 'binoculars',\n",
       " 'n02843684': 'birdhouse',\n",
       " 'n02859443': 'boathouse',\n",
       " 'n02860847': 'bobsled',\n",
       " 'n02865351': 'bolo',\n",
       " 'n02869837': 'bonnet',\n",
       " 'n02870880': 'bookcase',\n",
       " 'n02871525': 'bookshop',\n",
       " 'n02877765': 'bottlecap',\n",
       " 'n02879718': 'bow',\n",
       " 'n02883205': 'bow',\n",
       " 'n02892201': 'brass',\n",
       " 'n02892767': 'brassiere',\n",
       " 'n02894605': 'breakwater',\n",
       " 'n02895154': 'breastplate',\n",
       " 'n02906734': 'broom',\n",
       " 'n02909870': 'bucket',\n",
       " 'n02910353': 'buckle',\n",
       " 'n02916936': 'bulletproof',\n",
       " 'n02917067': 'bullet',\n",
       " 'n02927161': 'butcher',\n",
       " 'n02930766': 'cab',\n",
       " 'n02939185': 'caldron',\n",
       " 'n02948072': 'candle',\n",
       " 'n02950826': 'cannon',\n",
       " 'n02951358': 'canoe',\n",
       " 'n02951585': 'can',\n",
       " 'n02963159': 'cardigan',\n",
       " 'n02965783': 'car',\n",
       " 'n02966193': 'carousel',\n",
       " 'n02966687': 'carpenters',\n",
       " 'n02971356': 'carton',\n",
       " 'n02974003': 'car',\n",
       " 'n02977058': 'cash',\n",
       " 'n02978881': 'cassette',\n",
       " 'n02979186': 'cassette',\n",
       " 'n02980441': 'castle',\n",
       " 'n02981792': 'catamaran',\n",
       " 'n02988304': 'CD',\n",
       " 'n02992211': 'cello',\n",
       " 'n02992529': 'cellular',\n",
       " 'n02999410': 'chain',\n",
       " 'n03000134': 'chainlink',\n",
       " 'n03000247': 'chain',\n",
       " 'n03000684': 'chain',\n",
       " 'n03014705': 'chest',\n",
       " 'n03016953': 'chiffonier',\n",
       " 'n03017168': 'chime',\n",
       " 'n03018349': 'china',\n",
       " 'n03026506': 'Christmas',\n",
       " 'n03028079': 'church',\n",
       " 'n03032252': 'cinema',\n",
       " 'n03041632': 'cleaver',\n",
       " 'n03042490': 'cliff',\n",
       " 'n03045698': 'cloak',\n",
       " 'n03047690': 'clog',\n",
       " 'n03062245': 'cocktail',\n",
       " 'n03063599': 'coffee',\n",
       " 'n03063689': 'coffeepot',\n",
       " 'n03065424': 'coil',\n",
       " 'n03075370': 'combination',\n",
       " 'n03085013': 'computer',\n",
       " 'n03089624': 'confectionery',\n",
       " 'n03095699': 'container',\n",
       " 'n03100240': 'convertible',\n",
       " 'n03109150': 'corkscrew',\n",
       " 'n03110669': 'cornet',\n",
       " 'n03124043': 'cowboy',\n",
       " 'n03124170': 'cowboy',\n",
       " 'n03125729': 'cradle',\n",
       " 'n03126707': 'crane',\n",
       " 'n03127747': 'crash',\n",
       " 'n03127925': 'crate',\n",
       " 'n03131574': 'crib',\n",
       " 'n03133878': 'Crock',\n",
       " 'n03134739': 'croquet',\n",
       " 'n03141823': 'crutch',\n",
       " 'n03146219': 'cuirass',\n",
       " 'n03160309': 'dam',\n",
       " 'n03179701': 'desk',\n",
       " 'n03180011': 'desktop',\n",
       " 'n03187595': 'dial',\n",
       " 'n03188531': 'diaper',\n",
       " 'n03196217': 'digital',\n",
       " 'n03197337': 'digital',\n",
       " 'n03201208': 'dining',\n",
       " 'n03207743': 'dishrag',\n",
       " 'n03207941': 'dishwasher',\n",
       " 'n03208938': 'disk',\n",
       " 'n03216828': 'dock',\n",
       " 'n03218198': 'dogsled',\n",
       " 'n03220513': 'dome',\n",
       " 'n03223299': 'doormat',\n",
       " 'n03240683': 'drilling',\n",
       " 'n03249569': 'drum',\n",
       " 'n03250847': 'drumstick',\n",
       " 'n03255030': 'dumbbell',\n",
       " 'n03259280': 'Dutch',\n",
       " 'n03271574': 'electric',\n",
       " 'n03272010': 'electric',\n",
       " 'n03272562': 'electric',\n",
       " 'n03290653': 'entertainment',\n",
       " 'n03291819': 'envelope',\n",
       " 'n03297495': 'espresso',\n",
       " 'n03314780': 'face',\n",
       " 'n03325584': 'feather',\n",
       " 'n03337140': 'file',\n",
       " 'n03344393': 'fireboat',\n",
       " 'n03345487': 'fire',\n",
       " 'n03347037': 'fire',\n",
       " 'n03355925': 'flagpole',\n",
       " 'n03372029': 'flute',\n",
       " 'n03376595': 'folding',\n",
       " 'n03379051': 'football',\n",
       " 'n03384352': 'forklift',\n",
       " 'n03388043': 'fountain',\n",
       " 'n03388183': 'fountain',\n",
       " 'n03388549': 'fourposter',\n",
       " 'n03393912': 'freight',\n",
       " 'n03394916': 'French',\n",
       " 'n03400231': 'frying',\n",
       " 'n03404251': 'fur',\n",
       " 'n03417042': 'garbage',\n",
       " 'n03424325': 'gasmask',\n",
       " 'n03425413': 'gas',\n",
       " 'n03443371': 'goblet',\n",
       " 'n03444034': 'gokart',\n",
       " 'n03445777': 'golf',\n",
       " 'n03445924': 'golfcart',\n",
       " 'n03447447': 'gondola',\n",
       " 'n03447721': 'gong',\n",
       " 'n03450230': 'gown',\n",
       " 'n03452741': 'grand',\n",
       " 'n03457902': 'greenhouse',\n",
       " 'n03459775': 'grille',\n",
       " 'n03461385': 'grocery',\n",
       " 'n03467068': 'guillotine',\n",
       " 'n03476684': 'hair',\n",
       " 'n03476991': 'hair',\n",
       " 'n03478589': 'half',\n",
       " 'n03481172': 'hammer',\n",
       " 'n03482405': 'hamper',\n",
       " 'n03483316': 'hand',\n",
       " 'n03485407': 'handheld',\n",
       " 'n03485794': 'handkerchief',\n",
       " 'n03492542': 'hard',\n",
       " 'n03494278': 'harmonica',\n",
       " 'n03495258': 'harp',\n",
       " 'n03496892': 'harvester',\n",
       " 'n03498962': 'hatchet',\n",
       " 'n03527444': 'holster',\n",
       " 'n03529860': 'home',\n",
       " 'n03530642': 'honeycomb',\n",
       " 'n03532672': 'hook',\n",
       " 'n03534580': 'hoopskirt',\n",
       " 'n03535780': 'horizontal',\n",
       " 'n03538406': 'horse',\n",
       " 'n03544143': 'hourglass',\n",
       " 'n03584254': 'iPod',\n",
       " 'n03584829': 'iron',\n",
       " 'n03590841': 'jackolantern',\n",
       " 'n03594734': 'jean',\n",
       " 'n03594945': 'jeep',\n",
       " 'n03595614': 'jersey',\n",
       " 'n03598930': 'jigsaw',\n",
       " 'n03599486': 'jinrikisha',\n",
       " 'n03602883': 'joystick',\n",
       " 'n03617480': 'kimono',\n",
       " 'n03623198': 'knee',\n",
       " 'n03627232': 'knot',\n",
       " 'n03630383': 'lab',\n",
       " 'n03633091': 'ladle',\n",
       " 'n03637318': 'lampshade',\n",
       " 'n03642806': 'laptop',\n",
       " 'n03649909': 'lawn',\n",
       " 'n03657121': 'lens',\n",
       " 'n03658185': 'letter',\n",
       " 'n03661043': 'library',\n",
       " 'n03662601': 'lifeboat',\n",
       " 'n03666591': 'lighter',\n",
       " 'n03670208': 'limousine',\n",
       " 'n03673027': 'liner',\n",
       " 'n03676483': 'lipstick',\n",
       " 'n03680355': 'Loafer',\n",
       " 'n03690938': 'lotion',\n",
       " 'n03691459': 'loudspeaker',\n",
       " 'n03692522': 'loupe',\n",
       " 'n03697007': 'lumbermill',\n",
       " 'n03706229': 'magnetic',\n",
       " 'n03709823': 'mailbag',\n",
       " 'n03710193': 'mailbox',\n",
       " 'n03710637': 'maillot',\n",
       " 'n03710721': 'maillot',\n",
       " 'n03717622': 'manhole',\n",
       " 'n03720891': 'maraca',\n",
       " 'n03721384': 'marimba',\n",
       " 'n03724870': 'mask',\n",
       " 'n03729826': 'matchstick',\n",
       " 'n03733131': 'maypole',\n",
       " 'n03733281': 'maze',\n",
       " 'n03733805': 'measuring',\n",
       " 'n03742115': 'medicine',\n",
       " 'n03743016': 'megalith',\n",
       " 'n03759954': 'microphone',\n",
       " 'n03761084': 'microwave',\n",
       " 'n03763968': 'military',\n",
       " 'n03764736': 'milk',\n",
       " 'n03769881': 'minibus',\n",
       " 'n03770439': 'miniskirt',\n",
       " 'n03770679': 'minivan',\n",
       " 'n03773504': 'missile',\n",
       " 'n03775071': 'mitten',\n",
       " 'n03775546': 'mixing',\n",
       " 'n03776460': 'mobile',\n",
       " 'n03777568': 'Model',\n",
       " 'n03777754': 'modem',\n",
       " 'n03781244': 'monastery',\n",
       " 'n03782006': 'monitor',\n",
       " 'n03785016': 'moped',\n",
       " 'n03786901': 'mortar',\n",
       " 'n03787032': 'mortarboard',\n",
       " 'n03788195': 'mosque',\n",
       " 'n03788365': 'mosquito',\n",
       " 'n03791053': 'motor',\n",
       " 'n03792782': 'mountain',\n",
       " 'n03792972': 'mountain',\n",
       " 'n03793489': 'mouse',\n",
       " 'n03794056': 'mousetrap',\n",
       " 'n03796401': 'moving',\n",
       " 'n03803284': 'muzzle',\n",
       " 'n03804744': 'nail',\n",
       " 'n03814639': 'neck',\n",
       " 'n03814906': 'necklace',\n",
       " 'n03825788': 'nipple',\n",
       " 'n03832673': 'notebook',\n",
       " 'n03837869': 'obelisk',\n",
       " 'n03838899': 'oboe',\n",
       " 'n03840681': 'ocarina',\n",
       " 'n03841143': 'odometer',\n",
       " 'n03843555': 'oil',\n",
       " 'n03854065': 'organ',\n",
       " 'n03857828': 'oscilloscope',\n",
       " 'n03866082': 'overskirt',\n",
       " 'n03868242': 'oxcart',\n",
       " 'n03868863': 'oxygen',\n",
       " 'n03871628': 'packet',\n",
       " 'n03873416': 'paddle',\n",
       " 'n03874293': 'paddlewheel',\n",
       " 'n03874599': 'padlock',\n",
       " 'n03876231': 'paintbrush',\n",
       " 'n03877472': 'pajama',\n",
       " 'n03877845': 'palace',\n",
       " 'n03884397': 'panpipe',\n",
       " 'n03887697': 'paper',\n",
       " 'n03888257': 'parachute',\n",
       " 'n03888605': 'parallel',\n",
       " 'n03891251': 'park',\n",
       " 'n03891332': 'parking',\n",
       " 'n03895866': 'passenger',\n",
       " 'n03899768': 'patio',\n",
       " 'n03902125': 'payphone',\n",
       " 'n03903868': 'pedestal',\n",
       " 'n03908618': 'pencil',\n",
       " 'n03908714': 'pencil',\n",
       " 'n03916031': 'perfume',\n",
       " 'n03920288': 'Petri',\n",
       " 'n03924679': 'photocopier',\n",
       " 'n03929660': 'pick',\n",
       " 'n03929855': 'pickelhaube',\n",
       " 'n03930313': 'picket',\n",
       " 'n03930630': 'pickup',\n",
       " 'n03933933': 'pier',\n",
       " 'n03935335': 'piggy',\n",
       " 'n03937543': 'pill',\n",
       " 'n03938244': 'pillow',\n",
       " 'n03942813': 'pingpong',\n",
       " 'n03944341': 'pinwheel',\n",
       " 'n03947888': 'pirate',\n",
       " 'n03950228': 'pitcher',\n",
       " 'n03954731': 'plane',\n",
       " 'n03956157': 'planetarium',\n",
       " 'n03958227': 'plastic',\n",
       " 'n03961711': 'plate',\n",
       " 'n03967562': 'plow',\n",
       " 'n03970156': 'plunger',\n",
       " 'n03976467': 'Polaroid',\n",
       " 'n03976657': 'pole',\n",
       " 'n03977966': 'police',\n",
       " 'n03980874': 'poncho',\n",
       " 'n03982430': 'pool',\n",
       " 'n03983396': 'pop',\n",
       " 'n03991062': 'pot',\n",
       " 'n03992509': 'potters',\n",
       " 'n03995372': 'power',\n",
       " 'n03998194': 'prayer',\n",
       " 'n04004767': 'printer',\n",
       " 'n04005630': 'prison',\n",
       " 'n04008634': 'projectile',\n",
       " 'n04009552': 'projector',\n",
       " 'n04019541': 'puck',\n",
       " 'n04023962': 'punching',\n",
       " 'n04026417': 'purse',\n",
       " 'n04033901': 'quill',\n",
       " 'n04033995': 'quilt',\n",
       " 'n04037443': 'racer',\n",
       " 'n04039381': 'racket',\n",
       " 'n04040759': 'radiator',\n",
       " 'n04041544': 'radio',\n",
       " 'n04044716': 'radio',\n",
       " 'n04049303': 'rain',\n",
       " 'n04065272': 'recreational',\n",
       " 'n04067472': 'reel',\n",
       " 'n04069434': 'reflex',\n",
       " 'n04070727': 'refrigerator',\n",
       " 'n04074963': 'remote',\n",
       " 'n04081281': 'restaurant',\n",
       " 'n04086273': 'revolver',\n",
       " 'n04090263': 'rifle',\n",
       " 'n04099969': 'rocking',\n",
       " 'n04111531': 'rotisserie',\n",
       " 'n04116512': 'rubber',\n",
       " 'n04118538': 'rugby',\n",
       " 'n04118776': 'rule',\n",
       " 'n04120489': 'running',\n",
       " 'n04125021': 'safe',\n",
       " 'n04127249': 'safety',\n",
       " 'n04131690': 'saltshaker',\n",
       " 'n04133789': 'sandal',\n",
       " 'n04136333': 'sarong',\n",
       " 'n04141076': 'sax',\n",
       " 'n04141327': 'scabbard',\n",
       " 'n04141975': 'scale',\n",
       " 'n04146614': 'school',\n",
       " 'n04147183': 'schooner',\n",
       " 'n04149813': 'scoreboard',\n",
       " 'n04152593': 'screen',\n",
       " 'n04153751': 'screw',\n",
       " 'n04154565': 'screwdriver',\n",
       " 'n04162706': 'seat',\n",
       " 'n04179913': 'sewing',\n",
       " 'n04192698': 'shield',\n",
       " 'n04200800': 'shoe',\n",
       " 'n04201297': 'shoji',\n",
       " 'n04204238': 'shopping',\n",
       " 'n04204347': 'shopping',\n",
       " 'n04208210': 'shovel',\n",
       " 'n04209133': 'shower',\n",
       " 'n04209239': 'shower',\n",
       " 'n04228054': 'ski',\n",
       " 'n04229816': 'ski',\n",
       " 'n04235860': 'sleeping',\n",
       " 'n04238763': 'slide',\n",
       " 'n04239074': 'sliding',\n",
       " 'n04243546': 'slot',\n",
       " 'n04251144': 'snorkel',\n",
       " 'n04252077': 'snowmobile',\n",
       " 'n04252225': 'snowplow',\n",
       " 'n04254120': 'soap',\n",
       " 'n04254680': 'soccer',\n",
       " 'n04254777': 'sock',\n",
       " 'n04258138': 'solar',\n",
       " 'n04259630': 'sombrero',\n",
       " 'n04263257': 'soup',\n",
       " 'n04264628': 'space',\n",
       " 'n04265275': 'space',\n",
       " 'n04266014': 'space',\n",
       " 'n04270147': 'spatula',\n",
       " 'n04273569': 'speedboat',\n",
       " 'n04275548': 'spider',\n",
       " 'n04277352': 'spindle',\n",
       " 'n04285008': 'sports',\n",
       " 'n04286575': 'spotlight',\n",
       " 'n04296562': 'stage',\n",
       " 'n04310018': 'steam',\n",
       " 'n04311004': 'steel',\n",
       " 'n04311174': 'steel',\n",
       " 'n04317175': 'stethoscope',\n",
       " 'n04325704': 'stole',\n",
       " 'n04326547': 'stone',\n",
       " 'n04328186': 'stopwatch',\n",
       " 'n04330267': 'stove',\n",
       " 'n04332243': 'strainer',\n",
       " 'n04335435': 'streetcar',\n",
       " 'n04336792': 'stretcher',\n",
       " 'n04344873': 'studio',\n",
       " 'n04346328': 'stupa',\n",
       " 'n04347754': 'submarine',\n",
       " 'n04350905': 'suit',\n",
       " 'n04355338': 'sundial',\n",
       " 'n04355933': 'sunglass',\n",
       " 'n04356056': 'sunglasses',\n",
       " 'n04357314': 'sunscreen',\n",
       " 'n04366367': 'suspension',\n",
       " 'n04367480': 'swab',\n",
       " 'n04370456': 'sweatshirt',\n",
       " 'n04371430': 'swimming',\n",
       " 'n04371774': 'swing',\n",
       " 'n04372370': 'switch',\n",
       " 'n04376876': 'syringe',\n",
       " 'n04380533': 'table',\n",
       " 'n04389033': 'tank',\n",
       " 'n04392985': 'tape',\n",
       " 'n04398044': 'teapot',\n",
       " 'n04399382': 'teddy',\n",
       " 'n04404412': 'television',\n",
       " 'n04409515': 'tennis',\n",
       " 'n04417672': 'thatch',\n",
       " 'n04418357': 'theater',\n",
       " 'n04423845': 'thimble',\n",
       " 'n04428191': 'thresher',\n",
       " 'n04429376': 'throne',\n",
       " 'n04435653': 'tile',\n",
       " 'n04442312': 'toaster',\n",
       " 'n04443257': 'tobacco',\n",
       " 'n04447861': 'toilet',\n",
       " 'n04456115': 'torch',\n",
       " 'n04458633': 'totem',\n",
       " 'n04461696': 'tow',\n",
       " 'n04462240': 'toyshop',\n",
       " 'n04465501': 'tractor',\n",
       " 'n04467665': 'trailer',\n",
       " 'n04476259': 'tray',\n",
       " 'n04479046': 'trench',\n",
       " 'n04482393': 'tricycle',\n",
       " 'n04483307': 'trimaran',\n",
       " 'n04485082': 'tripod',\n",
       " 'n04486054': 'triumphal',\n",
       " 'n04487081': 'trolleybus',\n",
       " 'n04487394': 'trombone',\n",
       " 'n04493381': 'tub',\n",
       " 'n04501370': 'turnstile',\n",
       " 'n04505470': 'typewriter',\n",
       " 'n04507155': 'umbrella',\n",
       " 'n04509417': 'unicycle',\n",
       " 'n04515003': 'upright',\n",
       " 'n04517823': 'vacuum',\n",
       " 'n04522168': 'vase',\n",
       " 'n04523525': 'vault',\n",
       " 'n04525038': 'velvet',\n",
       " 'n04525305': 'vending',\n",
       " 'n04532106': 'vestment',\n",
       " 'n04532670': 'viaduct',\n",
       " 'n04536866': 'violin',\n",
       " 'n04540053': 'volleyball',\n",
       " 'n04542943': 'waffle',\n",
       " 'n04548280': 'wall',\n",
       " 'n04548362': 'wallet',\n",
       " 'n04550184': 'wardrobe',\n",
       " 'n04552348': 'warplane',\n",
       " 'n04553703': 'washbasin',\n",
       " 'n04554684': 'washer',\n",
       " 'n04557648': 'water',\n",
       " 'n04560804': 'water',\n",
       " 'n04562935': 'water',\n",
       " 'n04579145': 'whiskey',\n",
       " 'n04579432': 'whistle',\n",
       " 'n04584207': 'wig',\n",
       " 'n04589890': 'window',\n",
       " 'n04590129': 'window',\n",
       " 'n04591157': 'Windsor',\n",
       " 'n04591713': 'wine',\n",
       " 'n04592741': 'wing',\n",
       " 'n04596742': 'wok',\n",
       " 'n04597913': 'wooden',\n",
       " 'n04599235': 'wool',\n",
       " 'n04604644': 'worm',\n",
       " 'n04606251': 'wreck',\n",
       " 'n04612504': 'yawl',\n",
       " 'n04613696': 'yurt',\n",
       " 'n06359193': 'web',\n",
       " 'n06596364': 'comic',\n",
       " 'n06785654': 'crossword',\n",
       " 'n06794110': 'street',\n",
       " 'n06874185': 'traffic',\n",
       " 'n07248320': 'book',\n",
       " 'n07565083': 'menu',\n",
       " 'n07579787': 'plate',\n",
       " 'n07583066': 'guacamole',\n",
       " 'n07584110': 'consomme',\n",
       " 'n07590611': 'hot',\n",
       " 'n07613480': 'trifle',\n",
       " 'n07614500': 'ice',\n",
       " 'n07615774': 'ice',\n",
       " 'n07684084': 'French',\n",
       " 'n07693725': 'bagel',\n",
       " 'n07695742': 'pretzel',\n",
       " 'n07697313': 'cheeseburger',\n",
       " 'n07697537': 'hotdog',\n",
       " 'n07711569': 'mashed',\n",
       " 'n07714571': 'head',\n",
       " 'n07714990': 'broccoli',\n",
       " 'n07715103': 'cauliflower',\n",
       " 'n07716358': 'zucchini',\n",
       " 'n07716906': 'spaghetti',\n",
       " 'n07717410': 'acorn',\n",
       " 'n07717556': 'butternut',\n",
       " 'n07718472': 'cucumber',\n",
       " 'n07718747': 'artichoke',\n",
       " 'n07720875': 'bell',\n",
       " 'n07730033': 'cardoon',\n",
       " 'n07734744': 'mushroom',\n",
       " 'n07742313': 'Granny',\n",
       " 'n07745940': 'strawberry',\n",
       " 'n07747607': 'orange',\n",
       " 'n07749582': 'lemon',\n",
       " 'n07753113': 'fig',\n",
       " 'n07753275': 'pineapple',\n",
       " 'n07753592': 'banana',\n",
       " 'n07754684': 'jackfruit',\n",
       " 'n07760859': 'custard',\n",
       " 'n07768694': 'pomegranate',\n",
       " 'n07802026': 'hay',\n",
       " 'n07831146': 'carbonara',\n",
       " 'n07836838': 'chocolate',\n",
       " 'n07860988': 'dough',\n",
       " 'n07871810': 'meat',\n",
       " 'n07873807': 'pizza',\n",
       " 'n07875152': 'potpie',\n",
       " 'n07880968': 'burrito',\n",
       " 'n07892512': 'red',\n",
       " 'n07920052': 'espresso',\n",
       " 'n07930864': 'cup',\n",
       " 'n07932039': 'eggnog',\n",
       " 'n09193705': 'alp',\n",
       " 'n09229709': 'bubble',\n",
       " 'n09246464': 'cliff',\n",
       " 'n09256479': 'coral',\n",
       " 'n09288635': 'geyser',\n",
       " 'n09332890': 'lakeside',\n",
       " 'n09399592': 'promontory',\n",
       " 'n09421951': 'sandbar',\n",
       " 'n09428293': 'seashore',\n",
       " 'n09468604': 'valley',\n",
       " 'n09472597': 'volcano',\n",
       " 'n09835506': 'ballplayer',\n",
       " 'n10148035': 'groom',\n",
       " 'n10565667': 'scuba',\n",
       " 'n11879895': 'rapeseed',\n",
       " 'n11939491': 'daisy',\n",
       " 'n12057211': 'yellow',\n",
       " 'n12144580': 'corn',\n",
       " 'n12267677': 'acorn',\n",
       " 'n12620546': 'hip',\n",
       " 'n12768682': 'buckeye',\n",
       " 'n12985857': 'coral',\n",
       " 'n12998815': 'agaric',\n",
       " 'n13037406': 'gyromitra',\n",
       " 'n13040303': 'stinkhorn',\n",
       " 'n13044778': 'earthstar',\n",
       " 'n13052670': 'henofthewoods',\n",
       " 'n13054560': 'bolete',\n",
       " 'n13133613': 'ear',\n",
       " 'n15075141': 'toilet'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_path = label_path / 'synset_words.txt'\n",
    "\n",
    "def synset2word(synset_path=synset_path):\n",
    "    label_dict = {}\n",
    "    with open(synset_path, 'r') as f:\n",
    "        synset_word = f.readlines()\n",
    "        for i in range(len(synset_word)):\n",
    "            synset = synset_word[i].split()[0]\n",
    "            word = re.sub(r'[^a-zA-Z]', '', synset_word[i].split()[1])\n",
    "            label_dict[synset] = word\n",
    "            \n",
    "    return label_dict\n",
    "\n",
    "label_dict = synset2word()\n",
    "label_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, local_rank=0, no_save=False):\n",
    "        self.terminal = sys.stdout\n",
    "        self.file = None\n",
    "        self.local_rank = local_rank\n",
    "        self.no_save = no_save\n",
    "    def open(self, fp, mode=None):\n",
    "        if mode is None: mode = 'w'\n",
    "        if self.local_rank and not self.no_save == 0: self.file = open(fp, mode)\n",
    "    def write(self, msg, is_terminal=1, is_file=1):\n",
    "        if msg[-1] != \"\\n\": msg = msg + \"\\n\"\n",
    "        if self.local_rank == 0:\n",
    "            if '\\r' in msg: is_file = 0\n",
    "            if is_terminal == 1:\n",
    "                self.terminal.write(msg)\n",
    "                self.terminal.flush()\n",
    "            if is_file == 1 and not self.no_save:\n",
    "                self.file.write(msg)\n",
    "                self.file.flush()\n",
    "    def flush(self): \n",
    "        pass\n",
    "    \n",
    "def print_args(args, logger=None):\n",
    "    if logger is not None:\n",
    "        logger.write(\"#### configurations ####\")\n",
    "    for k, v in vars(args).items():\n",
    "        if logger is not None:\n",
    "            logger.write('{}: {}\\n'.format(k, v))\n",
    "        else:\n",
    "            print('{}: {}'.format(k, v))\n",
    "    if logger is not None:\n",
    "        logger.write(\"########################\")\n",
    "      \n",
    "import argparse\n",
    "import json\n",
    "def save_args(args, to_path):\n",
    "    with open(to_path, \"w\") as f:\n",
    "        json.dump(args.__dict__, f, indent=2)\n",
    "def load_args(from_path):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args()\n",
    "    with open(from_path, \"r\") as f:\n",
    "        args.__dict__ = json.load(f)\n",
    "    return args    \n",
    "\n",
    "class AverageMeter (object):\n",
    "    def __init__(self):\n",
    "        self.reset ()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def Accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        \n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * self.expansion),\n",
    "        )\n",
    "        self.expansion = 4\n",
    "        self.shortcut = nn.Sequential()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # 하위 layer로 내려갈때 downsampling(1/2줄이기)하면서 feature 수가 달라짐 그러므로 skip connection을 할 수 있게 보정\n",
    "        if stride != 1 or in_channels != out_channels * self.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        out = self.residual_function(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        return self.relu(out)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       BottleNeck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       BottleNeck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       BottleNeck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      BottleNeck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      BottleNeck-172           [-1, 2048, 7, 7]               0\n",
      "       AvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block=BottleNeck, layers=[3,4,6,3], in_channels=3, num_classes=1000):\n",
    "        self.num_classes = num_classes\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            \n",
    "        )        \n",
    "        self.conv2 = self._make_layer(block, 64, layers[0])\n",
    "        self.conv3 = self._make_layer(block, 128, layers[1], downsampling=True)\n",
    "        self.conv4 = self._make_layer(block, 256, layers[2], downsampling=True)\n",
    "        self.conv5 = self._make_layer(block, 512, layers[3], downsampling=True)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, num_blocks, downsampling=False):\n",
    "        if downsampling is True:\n",
    "            stride = 2\n",
    "        else:\n",
    "            stride = 1\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "import torchsummary\n",
    "model = ResNet()\n",
    "torchsummary.summary(model, (3,224,224), device='cpu')\n",
    "# print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [-m {alexnet,convnext_base,convnext_large,convnext_small,convnext_tiny,densenet121,densenet161,densenet169,densenet201,efficientnet_b0,efficientnet_b1,efficientnet_b2,efficientnet_b3,efficientnet_b4,efficientnet_b5,efficientnet_b6,efficientnet_b7,efficientnet_v2_l,efficientnet_v2_m,efficientnet_v2_s,get_weight,googlenet,inception_v3,mnasnet0_5,mnasnet0_75,mnasnet1_0,mnasnet1_3,mobilenet_v2,mobilenet_v3_large,mobilenet_v3_small,regnet_x_16gf,regnet_x_1_6gf,regnet_x_32gf,regnet_x_3_2gf,regnet_x_400mf,regnet_x_800mf,regnet_x_8gf,regnet_y_128gf,regnet_y_16gf,regnet_y_1_6gf,regnet_y_32gf,regnet_y_3_2gf,regnet_y_400mf,regnet_y_800mf,regnet_y_8gf,resnet101,resnet152,resnet18,resnet34,resnet50,resnext101_32x8d,resnext101_64x4d,resnext50_32x4d,shufflenet_v2_x0_5,shufflenet_v2_x1_0,shufflenet_v2_x1_5,shufflenet_v2_x2_0,squeezenet1_0,squeezenet1_1,swin_b,swin_s,swin_t,vgg11,vgg11_bn,vgg13,vgg13_bn,vgg16,vgg16_bn,vgg19,vgg19_bn,vit_b_16,vit_b_32,vit_h_14,vit_l_16,vit_l_32,wide_resnet101_2,wide_resnet50_2}]\n",
      "                             [-j N] [--epochs N] [--start-epoch N] [-b N]\n",
      "                             [--lr LR] [--momentum M] [--wd W] [-p N]\n",
      "                             [--resume PATH] [-e] [--world-size WORLD_SIZE]\n",
      "                             [--rank RANK] [--dist-url DIST_URL]\n",
      "                             [--dist-backend DIST_BACKEND] [--seed SEED]\n",
      "                             [--gpu GPU] [--multiprocessing-distributed]\n",
      "                             [--dummy]\n",
      "                             [DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"469f7a10-bb06-456b-8e21-829bf3d49b04\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/sangyong/.local/share/jupyter/runtime/kernel-v2-66738OweJaQ29CrXs.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangyong/anaconda3/envs/IMGNET/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn # cudnn.benchmark = True 최적의 backend 연산을 찾는 flag를 True로 함. ex)입력크기가 고정된 모델 등에 유효\n",
    "\n",
    "# for DDP\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from model.resnet50 import BottleNeck, ResNet\n",
    "from data.data import ImgNetData\n",
    "from utils import AverageMeter, Logger, print_args, save_args, load_args, Accuracy\n",
    "\n",
    "model_names = sorted(name for name in models.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "    and callable(models.__dict__[name]))\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Imagenet classifictation')\n",
    "parser.add_argument('data', metavar='DIR', nargs='?', default='/home/data/Imagenet',\n",
    "                    help='path to dataset') # metavar:인자의 이름지정, nargs 값 개수 지정\n",
    "parser.add_argument('-m','--model', default='resnet50', choices=model_names,\n",
    "                    help='model architecture: ' + ' | '.join(model_names) + ' (defalut: resnet50')\n",
    "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs of run')\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b','--batch_size', default=256, type=int, metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total batch size of all GPUs on the current node whe using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "parser.add_argument('-p', '--print-freq', default=10, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set') # dest: 적용 위치 지정, '-e'값이 args.evaluate에 저장되는것\n",
    "parser.add_argument('--world-size', default=-1, type=int,\n",
    "                    help='number of nodes for distributed training')\n",
    "parser.add_argument('--rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "parser.add_argument('--dist-url', default='tcp://10.201.134.133:8892', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "parser.add_argument('--seed', default=None, type=int,\n",
    "                    help='seed for initializing training. ')\n",
    "parser.add_argument('--gpu', default=None, type=int,\n",
    "                    help='GPU id to use.')\n",
    "parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                    help='Use multi-processing distributed training to launch '\n",
    "                         'N processes per node, which has N GPUs. This is the '\n",
    "                         'fastest way to use PyTorch for either single node or '\n",
    "                         'multi node data parallel training')\n",
    "parser.add_argument('--dummy', action='store_true', help=\"use fake data to benchmark\") # 제대로 돌아가는지 보기위한 Fake데이터\n",
    "\n",
    "best_acc1 = 0\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True # seed를 정했으므로 nondeterministic하지 않게 작업\n",
    "        cudnn.benchmark = False # 지금 환경에 가장 적합한 알고리즘을 찾을 필요가 없다.\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "    \n",
    "    if args.gpu is not None:\n",
    "        warnings.warn('You have chosen a specific GPU. This will completely disable data parallelism')\n",
    "        \n",
    "    if args.dist_url == \"env://\" and args.world_size == -1:\n",
    "        args.world_size = int(os.environ[\"WORLD_SIZE\"]) # local를 가정한건가??\n",
    "        print(args.world_size)\n",
    "        \n",
    "    args.distributed = args.world_size > 1 or args.multiprocessing_distributed\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        ngpus_per_node = torch.cuda.device_count() - 2 # GPU 0, 1번만 쓰기로 해서\n",
    "    else:\n",
    "        ngpus_per_node = 1\n",
    "        \n",
    "    if args.multiprocessing_distributed:\n",
    "        args.world_size = ngpus_per_node * args.world_size # 각 노드(machine)별 쓸 수 있는 gpu 다 합치기\n",
    "        # distributed processing 시작\n",
    "        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args)) # (fn:작동시킬 함수, nprocs:프로세서 갯수, args:fn에 넣을 args) / fn(i, *args) i is the process index\n",
    "    else:\n",
    "        # 단순하게 작동시킬 때\n",
    "        main_worker(args.gpu, ngpus_per_node, args)\n",
    "\n",
    "def main_worker(gpu, ngpus_per_node, args):\n",
    "    global best_acc1\n",
    "    # GPU 설정\n",
    "    print(gpu, ngpus_per_node)\n",
    "    args.gpu = gpu\n",
    "    \n",
    "    if args.gpu is not None:\n",
    "        print(\"use GPU: {} for training\".format(args.gpu))\n",
    "    \n",
    "    if args.distributed:\n",
    "        if args.dist_url == \"env://\" and args.rank == -1:\n",
    "            args.rank = int(os.environ[\"RANK\"])\n",
    "        if args.multiprocessing_distributed:\n",
    "            # gpu = 0,1,2 ... ngpus_per_node-1\n",
    "            args.rank=args.rank * ngpus_per_node + gpu\n",
    "        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size, rank=args.rank)\n",
    "        \n",
    "    # Model 설정\n",
    "    print(\"Creatin model '{}'\".format(args.model))\n",
    "    if args.dataset == 'imagenet':\n",
    "        num_classes = 1000\n",
    "    if args.model == 'resnet50':\n",
    "        model = ResNet(num_classes=num_classes)\n",
    "    elif args.model == 'vit':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('unknown model: {}'.format(args.model))\n",
    "    \n",
    "    # multiprocessing 설정\n",
    "    if not torch.cuda.is_available() and not torch.backends.mps.is_available():\n",
    "        print('using CPU, this will be slow') #gpu는 되는데 multiprocessing이 안될때?\n",
    "    elif args.distributed:\n",
    "        if args.gpu is not None:\n",
    "            torch.cuda.set_device(args.gpu)\n",
    "            model.cuda(args.gpu)\n",
    "            # when using a single GPU per process and per DDP, we need to divide tha batch size ourselves based on the total number of GPUs we have 왜지??\n",
    "            args.batch_size = int(args.batch_size / ngpus_per_node) # gpu에 나눠주기 위함이겠지?\n",
    "            args.worker = int((args.worker+ngpus_per_node-1)/ngpus_per_node) # 왜 이렇게해주지\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "        else:\n",
    "            model.cuda()\n",
    "            # 만약에 device_ids를 따로 설정해주지 않으면, 가능한 모든 gpu를 기준으로 ddp가 알아서 배치사이즈와 workers를 나눠준다는 뜻.\n",
    "            model = torch.nn.parallel.DistributedDataParallel(model)\n",
    "    elif args.gpu is not None:\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        model = model.cuda(args.gpu)\n",
    "        raise NotImplementedError(\"Only DistributedDataParallel is supported.\")\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only DistributedDataparallel is supported.\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        if args.gpu:\n",
    "            device = torch.device('cuda:{}'.format(args.gpu))\n",
    "        else:\n",
    "            device = torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "    # criterion & optimizer 정의\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "    \n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    \n",
    "    # 옵션1: resume 방법\n",
    "    if args.resume:\n",
    "        if os.path.isfile(args.resume):\n",
    "            print(\"=> loading checkpoint: '{}'\".format(args.resume))\n",
    "            if args.gpu is None:\n",
    "                checkpoint = torch.load(args.resume)\n",
    "            else:\n",
    "                # MAP model to be loaded to specific single gpu.\n",
    "                loc = 'cuda:{}'.format(args.gpu)\n",
    "                checkpoint = torch.load(args.resume, map_location=loc)\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            model.load_state_dict((checkpoint['state_dict']))\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(args.resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "            \n",
    "    if args.dummy:\n",
    "        print(\"=> Dummy data is used!\")\n",
    "        train_dataset = datasets.FakeData(1281167, (3, 224, 224), 1000, transforms.ToTensor())\n",
    "        val_dataset = datasets.FakeData(50000, (3, 224, 224), 1000, transforms.ToTensor())\n",
    "    else:\n",
    "        train_path = os.path.join(args.data, 'train')\n",
    "        val_path = os.path.join(args.data, 'val')\n",
    "        \n",
    "    train_dataset, val_dataset = ImgNetData(train_path, val_path)\n",
    "        \n",
    "    if args.distributed:\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False, drop_last=True)\n",
    "    else:\n",
    "        train_sampler = None\n",
    "        val_sampler = None\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None), num_workers=args.workers, pin_memory=True, sampelr=train_sampler)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, sampelr=val_sampler)\n",
    "    \n",
    "    if args.evaluate: # eval mode\n",
    "        validate(val_loader, model, criterion, args)\n",
    "        return\n",
    "    \n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        if args.distributed:\n",
    "            # 내용 6-1: train_sampler.set_epoch\n",
    "            # In distributed mode, calling the set_eopch() method at the beggining of \n",
    "            # each epoch before creating the \"dataloader\" iterator is necessary to make\n",
    "            # suffling work properly across multiple epochs. Otherwise, the same ordering will be always used.\n",
    "            train_sampler.set_epoch(epoch)  # 매 에폭마다 train_sampler.set_epoch(epoch)를 해주어야 shuffle이 잘 사용된다고 한다.\n",
    "            \n",
    "            train(train_loader, model, criterion, optimizer, epoch, device, args)\n",
    "            \n",
    "            acc1 = validate(val_loader, model, criterion, args)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            is_best = acc1 > best_acc1\n",
    "            best_acc1 = max(acc1, best_acc1)\n",
    "            \n",
    "            if not args.multiprocessing_distributed or (args.multiprocessing_distributed and args.rank % ngpus_per_node == 0):\n",
    "                save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'arch': args.arch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_acc1': best_acc1,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "                'scheduler' : scheduler.state_dict()\n",
    "            }, is_best)\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, device, args):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        data_time.update(time.time - end)\n",
    "        \n",
    "        # 또한 텐서 및 스토리지를 고정하면 비동기(asynchronous) GPU 복사본을 사용할 수 있습니다.\n",
    "        # 비동기식으로 GPU에 데이터 전달 기능을 추가하려면 non_blocking = True 인수를 to() 또는 cuda() 호출 시 argument로 전달하면 됩니다.\n",
    "        input = input.to(device, non_blocking=True)\n",
    "        target = target.to(device, non_blocking=True)\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        acc1 = Accuracy(output.data, target, topk=(1,))\n",
    "        \n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        acc1.update(acc1.item(), input.size(0))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_time.update(time.time - end)\n",
    "        end = time.time\n",
    "        \n",
    "        if 1 & args.print_freq == 0:\n",
    "            print('Epoch: [{0}/{1}][{2}/{3}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top 1-acc {top1.val:.4f} ({top1.avg:.4f})'.format(\n",
    "                epoch, args.epochs, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, top1=acc1))\n",
    "            \n",
    "    print('* Epoch: [{0}/{1}]\\t Top 1-err {top1.avg:.3f} Train Loss {loss.avg:.3f}'.format(\n",
    "        epoch, args.epochs, top1=acc1, loss=losses))\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "def validate(val_loader, model, criterion, args):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    acc1 = AverageMeter()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    end = time.time\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        acc1 = Accuracy(output, target)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        acc1.update(acc1.item(), input.size(0))\n",
    "        \n",
    "        batch_time.update(time.time - end)\n",
    "        end = time.time\n",
    "        \n",
    "        if 1 & args.print_freq == 0:\n",
    "            print('Test (on val set): [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.ave:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Top 1-acc {top1.val:.4f} ({top1.avg:.4f})'.format(\n",
    "                i, len(val_loader), batch_time=batch_time,\n",
    "                loss=losses, top1=acc1))\n",
    "    print('* Top 1-err {top1.avg:.3f}  Test Loss {loss.avg:.3f}'.format(\n",
    "        top1=acc1, loss=losses))\n",
    "    return acc1.avg, losses.avg\n",
    "\n",
    "def save_checkpoint(state, is_best,args, filename='checkpoint.pth.tar'):\n",
    "    directory = \"runs/%s/\" % (args.expname)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    filename = directory + filename\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'runs/%s/' % (args.expname) + 'model_best.pth.tar')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 30 11:45:30 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           On   | 00000000:3F:00.0 Off |                  N/A |\n",
      "| 41%   24C    P8    14W / 280W |  19314MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           On   | 00000000:42:00.0 Off |                  N/A |\n",
      "| 41%   28C    P8    12W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           On   | 00000000:60:00.0 Off |                  N/A |\n",
      "| 41%   24C    P8    15W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           On   | 00000000:65:00.0 Off |                  N/A |\n",
      "| 41%   24C    P8    16W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     37614      C   .../envs/diffuser/bin/python    19311MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMGNET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16 (default, Jan 17 2023, 22:20:44) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "8494cf7075c74e4f28217251c806f8ad3017af770baf78f62e6cb1283caa6097"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
