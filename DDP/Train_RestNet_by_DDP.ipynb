{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86e5708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "def load_dataset(args):\n",
    "    transform = transforms.Compose([ # Transforming and augmenting images\n",
    "        transforms.RandomHorizontalFlip(), # 랜덤 좌우 반전\n",
    "        transforms.RandomVerticalFlip(), # 랜덤 상하 반전\n",
    "        transforms.ColorJitter(), # 랜덤 색상필터\n",
    "        transforms.RandomResizedCrop((args.imgsz, args.imgsz)), # 랜덤으로 리사이즈 후, cropping\n",
    "        transforms.ToTensor(), # Tensor로 변환\n",
    "        transforms.Normalize((0.485, 0.465, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    \n",
    "    # 데이터셋 읽기\n",
    "    train_data = dset.ImageNet('../../../../media/data1/data/Imagenet', split='train', transform=transform)\n",
    "    test_data = dset.ImageNet('../../../../media/data1/data/Imagenet', split='val', transform=transform)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def pre_dset(rank, world_size, args):\n",
    "    assert not args.batch_size % world_size, \"batch size를 world size로 나뉘어져야 함, batch_size: \" + str(args.batch_size) + \", world_size: \" + str(world_size) + \", return value: \" + str(args.batch_size % world_size)\n",
    "    batch_per_gpu = args.batch_size // world_size # batch_size가 world_size의 몇 배인지(몫을 리턴)\n",
    "    if rank == 0:\n",
    "        print(f\"{batch_per_gpu} batches per GPU...\") # GPU 당 batch size\n",
    "        \n",
    "        \n",
    "    train_set, test_set = load_dataset(args)\n",
    "    \n",
    "    \n",
    "    # DDP로 분산 처리하기 위한 데이터 할당\n",
    "    train_sampler = DistributedSampler(train_set, # 데이터셋\n",
    "                                       num_replicas=world_size, # process 개수\n",
    "                                       rank=rank, # process ID\n",
    "                                       shuffle=args.shuffle, # shuffle 여부(DDP는 True, 단일은 False)\n",
    "                                      )\n",
    "    test_sampler = DistributedSampler(test_set,\n",
    "                                      num_replicas=world_size, # process 개수\n",
    "                                      rank=rank, # process ID\n",
    "                                      shuffle=False, # Test set은 섞을 필요 없음\n",
    "                                     )\n",
    "    \n",
    "    # DataLoader\n",
    "    train_loader = DataLoader(train_set, # 데이터 셋\n",
    "                              batch_size=batch_per_gpu, # GPU에 맞는 batch size(CPU는 그냥 batch_size)\n",
    "                              pin_memory=args.pin_memory, # CPU에서 GPU의 VRAM으로 데이터를 로드해주기 위한 CPU의 Pinned memory\n",
    "                              num_workers=args.num_workers, # 데이터 프로세싱 시 CPU 코어 할당량\n",
    "                              sampler=train_sampler,\n",
    "                              shuffle=not args.shuffle,  # shuffle옵션의 디폴트는 False이지만 여기서는 유동적으로 변경하였음\n",
    "                             )\n",
    "    test_loader = DataLoader(test_set,\n",
    "                             batch_size=batch_per_gpu,\n",
    "                             pin_memory=args.pin_memory, # CPU에서 GPU의 VRAM으로 데이터를 로드해주기 위한 CPU의 Pinned memory\n",
    "                             num_workers=args.num_workers, # 데이터 프로세싱 시 CPU 코어 할당량\n",
    "                             sampler=test_sampler,\n",
    "                             shuffle=False\n",
    "                            )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, rank, args) -> (float, float):\n",
    "    model.train() # 학습을 위한 train mode로 변경\n",
    "    running_loss, logging_loss, train_acc = 0, 0, 0  # 학습 loss, 로그 출력용 loss, 학습 Accuracy\n",
    "    for epoch, (data, label) in enumerate(train_loader, 1):\n",
    "        if args.pin_memory: # 고정된 메모리\n",
    "            data, label = data.to(rank, non_blocking=True), label.to(rank, non_blocking=True) # non_blocking: 비동기로 GPU에 객체를 전달\n",
    "        else:\n",
    "            data, label = datda.to(rank), label.to(rank) # process Id만 지정\n",
    "    \n",
    "        out = model(data) # 모델에 데이터 넣기\n",
    "        loss = criterion(out, label) # loss 함수로 입력과 라벨의 loss 구하기\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        logging_loss += loss.item()\n",
    "        if rank == 0:\n",
    "            if not epoch % args.every: # 정해진 수마다 출력 (나눈 값의 나머지가 0이면 출력됨)\n",
    "                print(f\"[{args.epoch}/{len(train_loader)}] loss: {logging_loss / args.every}\")\n",
    "                logging_loss = 0\n",
    "\n",
    "        train_acc += (out.detach().argmax(-1) == label).float().sum() / args.batch_size # accuracy\n",
    "\n",
    "        optimizer.zero_grad() # 학습마다 기울기를 0으로 초기화\n",
    "        loss.backward() # 가중치와 편향을 계산\n",
    "        optimizer.step() # 가중치 업데이트\n",
    "\n",
    "        return running_loss / len(train_loader), train_acc /len(train_loader) # loss 및 acc 리턴\n",
    "\n",
    "def validate(model, val_loader, criterion, rank, args):\n",
    "    model.eval() # 검증 시에는 Batch Normalization과 Dropout를 학습과 다르게 설정해야 함\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader:\n",
    "            data, label = data.to(rank), label.to(rank)\n",
    "            \n",
    "            out = model(data) # 모델에 데이터 넣기\n",
    "            loss = criterion(out, label) # loss 함수로 입력과 라벨의 loss 구하기\n",
    "            \n",
    "            val_acc += (out.detach().argmax(-1) == label).float().sum() / args.batch_size # val accuracy\n",
    "            val_loss += loss # val loss\n",
    "            \n",
    "        return val_acc / len(val_loader), val_loss / len(val_loader) # val loss 및 val acc 리턴\n",
    "    \n",
    "def save_ckpt(state, file_name=\"./model_checkpoint/best_model.pth\") -> None:\n",
    "    torch.save(state, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f00364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--exp EXP] [--lr LR] [--epochs EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE] [--every EVERY]\n",
      "                             [--step_size STEP_SIZE] [--gamma GAMMA]\n",
      "                             [--pin_memory] [--num_workers NUM_WORKERS]\n",
      "                             [--shuffle] [--imgsz IMGSZ]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/kangjun/.local/share/jupyter/runtime/kernel-ef463698-9fbe-4c6e-b8bd-6ff159b6ecdb.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kangjun/anaconda3/envs/torch0126/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "from sched import scheduler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from ResNet import ResNet, Bottleneck\n",
    "from prepare_dataset import pre_dset\n",
    "from train import train, validate\n",
    "from utils import save_ckpt\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Imagenet Training\")\n",
    "    \n",
    "    ## Config\n",
    "    parser.add_argument(\"--exp\", type=str, default=\"./model_checkpoint\") # checkpoint를 저장할 경로\n",
    "    \n",
    "    ## Training\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4) # 학습률\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100) # 학습 횟수\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32) # batch size\n",
    "    parser.add_argument(\"--every\", type=int, default=100) # 학습 중간에 loss를 출력할 빈도 수\n",
    "    parser.add_argument(\"--step_size\", type=int, default=30) # StepLR의 step_size\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.1) # StepLR의 gamma\n",
    "    \n",
    "    ## Data loader\n",
    "    parser.add_argument(\"--pin_memory\", action='store_true') # 데이터를 CPU -> GPU로 옮길 때 사용할 memory(store_true: True를 저장)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=2) # DataLoder에서 사용할 CPU 코어 개수\n",
    "    parser.add_argument(\"--shuffle\", action='store_true') # DDP의 DistributedSampler에서 shuffle의 여부이며, Data Loader는 이와 반대로 지정(store_true: True를 저장)\n",
    "    parser.add_argument(\"--imgsz\", type=int, default=600) # RandomResizedCrop 시 crop output의 image size 지정\n",
    "\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=0) # GPU process ID\n",
    "    return parser.parse_args() # 입력받은 argument 리턴\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group() # 분산 학습 완료 후, 프로세스 초기화\n",
    "    \n",
    "def main(rank, world_size, args):\n",
    "    torch.cuda.set_device(rank) # GPU의 각 프로세스 세팅\n",
    "    \n",
    "    train_loader, val_loader = pre_dset(rank, world_size, args) # 데이터 불러오기 및 전처리\n",
    "    \n",
    "    model = ResNet(Bottleneck, [3,4,6,3]).to(rank) # model 생성자\n",
    "    model = DDP(model, device_ids=[rank], output_device=rank) # 병렬 처리를 위해 DDP에 model, process id를 넘겨줌\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr) # 최적화기법 및 learning rate 설정\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma) # learning rate를 step_size마다 gamma를 곱하여 감소시킴\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    if rank == 0: print(f\"Start Imagenet Training\")\n",
    "    best_acc, best_loss = 0., float(\"inf\") # Best value 초기화 시 acc는 가장 낮은 값, loss는 무한으로 설정\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        train_loader.sampler.set_epoch(epoch) # epoch마다 DistributedSampler에게 현재 epoch을 계속 전달해야 함\n",
    "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, rank, args) # Train\n",
    "    \n",
    "        val_acc, val_loss = validate(model, val_loader, criterion, rank, args)\n",
    "        \n",
    "        ## reason of using ones_like: \n",
    "        ## the container's value should be on the same device with the value it will contain\n",
    "        g_acc = [torch.ones_like(val_acc) for _ in range(world_size)]\n",
    "        g_loss = [torch.ones_like(val_loss) for _ in range(world_size)]\n",
    "\n",
    "        # DistributedDataParallel.all_gather: 모든 프로세스의 tensor 를 모든 프로세스의 tensor_list 에 복사\n",
    "        dist.all_gather(g_acc, val_acc)\n",
    "        dist.all_gather(g_loss, val_loss)\n",
    "\n",
    "        if rank == 0: # 첫 번째 GPU process\n",
    "            val_acc = torch.stack(g_acc, dim=0) # torch.stack: 새로운 차원에 Tensor를 붙임\n",
    "            val_loss = torch.stack(g_loss, dim=0)\n",
    "            val_acc, val_loss = val_acc.mean(), val_loss.mean()\n",
    "            print(f\"EPOCH {epoch} VALID: acc = {val_acc}, loss = {val_loss}\") # EPOCH 당 accuracy 및 loss 출력\n",
    "            if val_acc > best_acc: # best accuracy 찾기\n",
    "                save_ckpt ({\n",
    "                    \"epoch\": epoch+1, # 왜 1을 더해\n",
    "                    \"state_dict\": model.module.state_dict(), # 학습된 모델 저장\n",
    "                    \"optimizer\": optimizer.state_dict(), # optimizer 저장\n",
    "                    \"scheduler\": scheduler.state_dict(), # scheduler 저장\n",
    "                }, file_name=os.path.join(args.exp, f\"best_acc.pth\")) # best loss 저장\n",
    "            if val_loss > best_loss: # best loss 찾기\n",
    "                save_ckpt({\n",
    "                    \"epoch\": epoch+1,\n",
    "                    \"state_dict\": model.module.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"scheduler\": scheduler.state_dict(),\n",
    "                }, file_name=os.path.join(args.exp, f\"best_loss.path\"))\n",
    "            save_ckpt({\n",
    "                \"epoch\": epoch+1,\n",
    "                \"state_dict\": model.module.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"scheduler\": scheduler.state_dict(),\n",
    "            }, file_name=os.path.join(args.exp, f\"last.pth\"))\n",
    "        scheduler.step() # scheduler 업데이트\n",
    "        # we do not need it when training, since DDP automatically does it for us (in loss.backward());\n",
    "        # we do not need it when gathering data, since dist.all_gather_object does it for us;\n",
    "        # we need it when enforcing execution order of codes, say one process loads the model that another process saves (I can hardly imagine this scenario is needed).\n",
    "        dist.barrier() # 모든 프로세스가 동기화되도록 맞춰줌\n",
    "    \n",
    "    cleanup()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args() # argument 받기\n",
    "    args.local_rank = int(os.environ['LOCAL_RANK']) # torchrun 사용을 위한 Local Rank 전달\n",
    "    print(args)\n",
    "    \n",
    "    dist.init_process_group(\"nccl\")\n",
    "    \n",
    "    if \"./model_checkpoint\" not in args.exp: # 입력 받은 경로에 해당 폴더가 없으면\n",
    "        args.exp = os.path.join(\"./model_checkpoint\", args.exp) # 경로를 이어붙임\n",
    "    os.makedirs(args.exp, exist_ok=True) # exist_ok=True: 폴더가 없으면 자동 생성\n",
    "    \n",
    "    main(rank=args.local_rank, world_size=dist.get_world_size(), args=args) # main에 GPU의 process ID, process 수 및 args를 넘겨줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e3445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prac_torch0126",
   "language": "python",
   "name": "prac_torch0126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
